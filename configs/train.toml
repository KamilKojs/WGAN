seed = 42
output_dir = "models"

[data_args]
train_dataset_dir = './data'
train_batch_size = 8
num_workers = 4

[model_args]
learning_rate = 2e-5

[trainer_args]
limit_train_batches = 250
#gpus = -1
#accelerator = "ddp"

[early_stopping_args]
monitor = 'D_loss'
patience = 3